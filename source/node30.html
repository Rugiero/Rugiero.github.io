<!DOCTYPE HTML>

<!--Converted with LaTeX2HTML 2024 (Released January 1, 2024) -->
<HTML lang="en">
<HEAD>
<TITLE>November&mdash;Artificial intelligence, machine learning, hypothesis classes, and stochastic geometry</TITLE>

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="viewport" CONTENT="width=device-width, initial-scale=1.0">
<META NAME="Generator" CONTENT="LaTeX2HTML v2024">

<LINK REL="STYLESHEET" HREF="source.css">

<LINK REL="previous" HREF="node29.html">
<LINK REL="next" HREF="node31.html">
</HEAD>

<BODY >

<DIV CLASS="navigation"><!--Navigation Panel-->
<A
 HREF="node31.html">
<IMG WIDTH="37" HEIGHT="24" ALT="next" SRC="next.png"></A> 
<A
 HREF="node29.html">
<IMG WIDTH="26" HEIGHT="24" ALT="up" SRC="up.png"></A> 
<A
 HREF="node29.html">
<IMG WIDTH="63" HEIGHT="24" ALT="previous" SRC="prev.png"></A> 
<A ID="tex2html274"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALT="contents" SRC="contents.png"></A>  <A ID="tex2html1"
  HREF="cv.pdf"><IMG
 STYLE="" SRC="jetscalecropped.png"
 ALT="7"></A>
<BR>
<B> Next:</B> <A
 HREF="node31.html">About this document ...</A>
<B> Up:</B> <A
 HREF="node29.html">Blog posts 2025</A>
<B> Previous:</B> <A
 HREF="node29.html">Blog posts 2025</A>
 &nbsp; <B>  <A ID="tex2html275"
  HREF="node1.html">Contents</A></B> 
<BR>
<BR></DIV>
<!--End of Navigation Panel-->

<H2><A ID="SECTION00071000000000000000">
November&mdash;Artificial intelligence, machine learning, hypothesis classes, and stochastic geometry</A>
</H2>

<P>
The obvious trend that <A ID="tex2html117"
  HREF="https://en.wikipedia.org/wiki/Artificial_intelligence">artificial intelligence</A>
(AI) and <A ID="tex2html118"
  HREF="https://en.wikipedia.org/wiki/Machine_learning">machinge learning</A>
(ML) are the hot topic of the day. This is why want to address how <A ID="tex2html119"
  HREF="https://en.wikipedia.org/wiki/Stochastic_geometry_models_of_wireless_networks">stochastic geometry</A>
(SG) can and will be utilized in the modern ML by providing <SPAN  CLASS="textbf">hypothesis classes</SPAN> for the ML algorithms.

<P>
Sometimes one hears that SG and ML has are as far as rivals: if so, the ML community may declare the victory of the battle, maybe for the entire war, given the purely economical performance meters: SG has transformed from an academic exercise into the industry only in marginal sense; however, as of today, the ML is encompassed everywhere in the industry and academy. However, I am sure that most people agree that such rivalry is not the only way to see the situation. So is the (extensively ongoing) study of SG useless?  It definitely is not. Let us address why. 

<P>
Le me formulate the working definitions of the ML and SG. We focus on the signal processing of wireless networks aspects, and particularly interference modeling and its statistical inference.
                 
<UL>
<LI>SG encompasses random <SPAN  CLASS="textbf">models</SPAN> of wireless networks, from which many statistical properties; such as of interference and its temporal and spatial correlations. The expressions are usually presented in mathematical forms; at best in tractable and closed form formulas are avalaible. 
</LI>
<LI>ML encompasses learning algorithms, from which many statistical properties can be numerically many times presented according to the past <SPAN  CLASS="textbf">raw-data</SPAN>, such as interference prediction including its temporal and spatial correlation properties. The results are essentially numerical.
                 
</LI>
</UL>

<P>
ML algorithms are often based in <A ID="tex2html120"
  HREF="https://en.wikipedia.org/wiki/Kriging">Gaussian process regression</A>
(GPR). The landscape of such algorithms is vast. The GPR signal prediction is based in prior autocovariance, or more generally, correlation functions, which can be arbitrary. One may numerically estimate the autocovariance from empirical data; however, this approach can lead to uncontrollable numerical cliches. Hence, it is usefull to base the estimations in a theoretical estimate of the correlation functions, which guides us to right direction in infering the empirical data at hand. (For example, the numerical estimations of <A ID="tex2html121"
  HREF="https://en.wikipedia.org/wiki/Autocorrelation">autocovariance</A>
function may fluctuate vastly, depending on the sampled realization of the data, even though the data statistics would in principle be invariant.) In the following, we demonstrate a simple example of estimating the power of a non-stationary Gaussian interference signal at a <A ID="tex2html122"
  HREF="https://en.wikipedia.org/wiki/Low_Earth_orbit">low Earth orbit</A>
base station (LEO BS). The prior autocovariance function is derived from a theoretical estimate based in SG, and based in this autocovariance, the power estimation is conducted from empirical data by using GPR.

<P>
The theoretical settings are:
                 
<OL>
<LI>The interferers (natural sources or tranmitters) with the bandiwdth <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.72ex; vertical-align: -0.12ex; " SRC="img154.svg"
 ALT="$1$"></SPAN> kHz are distributed according to the <A ID="tex2html114"
  HREF="https://en.wikipedia.org/wiki/Poisson_point_process">Poisson point process</A>
(PPP) on the Earth surface causing interference at the LEO BS. 
</LI>
<LI>The LEO BS has a narrow beam of <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.92ex; vertical-align: -0.31ex; " SRC="img155.svg"
 ALT="$-3$"></SPAN> dB beamwidth <!-- MATH
 $\varphi_{\text{RX}}=1.6^{\circ} = 0.027925$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 2.28ex; vertical-align: -0.57ex; " SRC="img156.svg"
 ALT="$\varphi_{\text{RX}}=1.6^{\circ} = 0.027925$"></SPAN> rad steered towards the Earth center.
</LI>
<LI>The LEO BS is at <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.84ex; vertical-align: -0.12ex; " SRC="img157.svg"
 ALT="$h=200$"></SPAN> km moving at its orbital speed <!-- MATH
 $v_{\text{sat}}=7.4$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 2.07ex; vertical-align: -0.46ex; " SRC="img158.svg"
 ALT="$v_{\text{sat}}=7.4$"></SPAN> km/s.
</LI>
<LI>For simplicity, no fast-<A ID="tex2html115"
  HREF="https://en.wikipedia.org/wiki/Fading">fading</A>, Shadowing or other attenuation is considered. For the narrow beam, the Doppler shifts are very close to each other for all tranmitters
                 
</LI>
</OL>
                 As the LEO BS move, the magnitude of the aggregate interference varies due to the PPP distributed interferers.

<P>
The key insight acquired from the SG is that in such settings, the normalized interference power <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img159.svg"
 ALT="$P=P(t)$"></SPAN> at the LEO BS is closely <A ID="tex2html123"
  HREF="https://en.wikipedia.org/wiki/Gamma_distribution">gamma distributed</A>
with the mean <!-- MATH
 $\mathbb{E}(P)=1$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img160.svg"
 ALT="$\mathbb{E}(P)=1$"></SPAN> and the variance <!-- MATH
 $\text{var}(P)=1/2$
 -->
<SPAN CLASS="MATH">var<IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img161.svg"
 ALT="$(P)=1/2$"></SPAN>. Furthermore, the autocovariance at lag <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.23ex; vertical-align: -0.12ex; " SRC="img162.svg"
 ALT="$\tau$"></SPAN> has the Gaussian form <!-- MATH
 $K_{P}(\tau)=\kappa \exp\left\{D\tau^2 \log(2)\right\}=1/2 \exp\left\{v_{\text{sat}}^2\tau^2/(h^2 \varphi_{\text{RX}}^2) \log(2)\right\}$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 3.01ex; vertical-align: -0.93ex; " SRC="img163.svg"
 ALT="$K_{P}(\tau)=\kappa \exp\left\{D\tau^2 \log(2)\right\}=1/2 \exp\left\{v_{\text{sat}}^2\tau^2/(h^2 \varphi_{\text{RX}}^2) \log(2)\right\}$"></SPAN>. This is the prior <A ID="tex2html124"
  HREF="https://en.wikipedia.org/wiki/Correlation">correlation</A>
model we will utilize in the GPR: the decribed <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img164.svg"
 ALT="$P(t)$"></SPAN> is the hypothesis class of the set of functions within which we search our estimation.

<P>
Note that the constant <!-- MATH
 $D=v_{\text{sat}}^2\tau^2/(h^2 \varphi_{\text{RX}}^2)$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 2.75ex; vertical-align: -0.76ex; " SRC="img165.svg"
 ALT="$D=v_{\text{sat}}^2\tau^2/(h^2 \varphi_{\text{RX}}^2)$"></SPAN> is directly defined by the altitude <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.84ex; vertical-align: -0.12ex; " SRC="img166.svg"
 ALT="$h$"></SPAN> of the satellite: the <A ID="tex2html125"
  HREF="https://en.wikipedia.org/wiki/Orbital_speed">orbital speed</A>
<!-- MATH
 $v_{\text{sat}}$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 1.58ex; vertical-align: -0.46ex; " SRC="img167.svg"
 ALT="$v_{\text{sat}}$"></SPAN> follows single-handly from the altitude. On the contrary, the scaling parameter <!-- MATH
 $\kappa=1/2$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img168.svg"
 ALT="$\kappa=1/2$"></SPAN> would have generally a dependency on the density of the interferers (in our case, the received power being normalized). However, it can be empirically verified that within a fairly general density region, the assertion of <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.81ex; vertical-align: -0.12ex; " SRC="img169.svg"
 ALT="$D$"></SPAN> is more crucial for the GPR estimation: too large and small <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.81ex; vertical-align: -0.12ex; " SRC="img169.svg"
 ALT="$D$"></SPAN> leads to <A ID="tex2html126"
  HREF="https://en.wikipedia.org/wiki/Overfitting">overfitting</A>
and underfitting of the data, respectively. On the other hand, these two parameters can be also set as <A ID="tex2html127"
  HREF="https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)">hyperparameters</A>
that are learned from the data&mdash;of course, also in this case, the proposed SG-based hypothesis class of <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img164.svg"
 ALT="$P(t)$"></SPAN> encompasses important insights through its the gamma distribution and the Gaussian correlation function.

<P>
Furthermore, it can be shown that, under fairly general settings, the LEO BS receives a waveform <!-- MATH
 $I(t)=\sqrt{P(t)}X(t)$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 3.10ex; vertical-align: -0.82ex; " SRC="img170.svg"
 ALT="$I(t)=\sqrt{P(t)}X(t)$"></SPAN>, where <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img171.svg"
 ALT="$X(t)$"></SPAN> is a near-Gaussian noise waveform. This means that <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img172.svg"
 ALT="$I(t)$"></SPAN> can be approximated by a non-stationary Gaussian process with the varying variance <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img164.svg"
 ALT="$P(t)$"></SPAN>. We will sample <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.69ex; vertical-align: -0.70ex; " SRC="img173.svg"
 ALT="$\vert I(t)\vert^2$"></SPAN> to estimate the interference power <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img164.svg"
 ALT="$P(t)$"></SPAN>.

<P>
In Figures 1(a) and 1(b), we estimate the interference power <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img164.svg"
 ALT="$P(t)$"></SPAN> from a sampled (sampling frequency <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.72ex; vertical-align: -0.12ex; " SRC="img174.svg"
 ALT="$0.1$"></SPAN> kHz) realization of <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img172.svg"
 ALT="$I(t)$"></SPAN> by using GPR and (non-<A ID="tex2html128"
  HREF="https://en.wikipedia.org/wiki/Causal_filter">causal</A>) <A ID="tex2html129"
  HREF="https://en.wikipedia.org/wiki/Moving_average">moving average</A>
(MA). (The window size of the MA is empirically optimized.) The power modulator <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img164.svg"
 ALT="$P(t)$"></SPAN> is generated through a latent <A ID="tex2html130"
  HREF="https://en.wikipedia.org/wiki/Gaussian_process">Gaussian process</A>
based in the gamma distribution and the second-order statistics, which we accept as a sufficient approximation (the &ldquo;actual&rdquo; <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img164.svg"
 ALT="$P(t)$"></SPAN> should be generated by moving the LEO BS over the PPP distributed interferers on the Earth surface).

<P>
Altough the MA might capture <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img164.svg"
 ALT="$P(t)$"></SPAN> reasonably well (as long as the window size is optimized), the GPR prediction is clearly able to better capture the smootheness of the signal power modulating the Gaussian noise. Furthermore, the GPR prediction captures the <SPAN CLASS="MATH"><IMG
 STYLE="height: 2.55ex; vertical-align: -0.70ex; " SRC="img164.svg"
 ALT="$P(t)$"></SPAN> from <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.72ex; vertical-align: -0.12ex; " SRC="img175.svg"
 ALT="$t=0$"></SPAN> onwards, which is impossible for the non-causal, centralized MA, which starts at <!-- MATH
 $t\approx 1.5$
 -->
<SPAN CLASS="MATH"><IMG
 STYLE="height: 1.72ex; vertical-align: -0.12ex; " SRC="img176.svg"
 ALT="$t\approx 1.5$"></SPAN>s. The <A ID="tex2html131"
  HREF="https://en.wikipedia.org/wiki/Predictive_analytics">forecast</A>
region in the figure corresponds to a causal estimation of the signal future based in the past values: Not so suprisingly, the GPR is suprerior to MA in this regard.

<P>

<DIV class="CENTER"><A ID="797"></A>
<TABLE>
<CAPTION class="BOTTOM"><STRONG>Figure:</STRONG>
The baseband signal under Rayleigh fading <SPAN CLASS="MATH"><IMG
 STYLE="height: 1.81ex; vertical-align: -0.12ex; " SRC="img143.svg"
 ALT="$K=0$"></SPAN>.</CAPTION>
<TR><TD><IMG
 STYLE="height: 48.13ex; vertical-align: -0.12ex; " SRC="img177.svg"
 ALT="\includegraphics[width=\linewidth]{GPRvsMA.pdf}"></TD></TR>
</TABLE>
</DIV>

<P>

<DIV CLASS="navigation"><HR>
<!--Navigation Panel-->
<A
 HREF="node31.html">
<IMG WIDTH="37" HEIGHT="24" ALT="next" SRC="next.png"></A> 
<A
 HREF="node29.html">
<IMG WIDTH="26" HEIGHT="24" ALT="up" SRC="up.png"></A> 
<A
 HREF="node29.html">
<IMG WIDTH="63" HEIGHT="24" ALT="previous" SRC="prev.png"></A> 
<A ID="tex2html274"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALT="contents" SRC="contents.png"></A>  <A ID="tex2html1"
  HREF="cv.pdf"><IMG
 STYLE="" SRC="jetscalecropped.png"
 ALT="7"></A>
<BR>
<B> Next:</B> <A
 HREF="node31.html">About this document ...</A>
<B> Up:</B> <A
 HREF="node29.html">Blog posts 2025</A>
<B> Previous:</B> <A
 HREF="node29.html">Blog posts 2025</A>
 &nbsp; <B>  <A ID="tex2html275"
  HREF="node1.html">Contents</A></B> </DIV>
<!--End of Navigation Panel-->

</BODY>
</HTML>
